---
name: ai-cartographer
description: Open-source CLI tool that generates and maintains AI-optimized semantic context maps for codebases
status: backlog
created: 2026-02-17T16:14:55Z
repo: gilpaAI/ai-cartographer
---

# PRD: ai-cartographer

## Executive Summary

Project Cartographer is an open-source CLI tool that generates and maintains a live, compressed "context map" of any code repository. Just as humans need a README to understand a project, AI agents need a semantic index. Cartographer creates this index automatically — a single file (`.ai/context-map.md`) that describes *what each file does* rather than just listing paths. It uses an **LLM-first approach** — all semantic descriptions are generated by AI, with aggressive cost optimizations (content-hash caching, batched analysis, tiered file classification, and model routing) to keep API costs minimal even for large repos. Auto-maintains itself via git hooks, and installs with a single CLI command. MIT licensed, designed for universal adoption across Cursor, Claude Code, Copilot, and any LLM-powered dev tool.

## Problem Statement

When AI agents enter a codebase, they are "blind." They have no structural understanding of where logic lives, which files handle what concerns, or how modules relate. This leads to:

- **Token waste** — agents read random files trying to orient themselves
- **Hallucinated paths** — agents guess file locations that don't exist
- **Context drift** — agents lose track of the codebase structure mid-task
- **Low-quality edits** — without understanding the architecture, agents make changes in the wrong places
- **High API costs** — exploration burns tokens before productive work even begins

Current solutions (`tree`, `find`, `ls`) show file structure but not intent. There is no standard for AI-native documentation that tells an agent "this file handles JWT validation" vs "this file is a test fixture."

## Target Users

### Primary: AI-Augmented Developers
Developers who use AI coding assistants (Cursor, Claude Code, Copilot) daily and want their agents to work faster and more accurately.

### Secondary: AI Tool Builders
Teams building AI agents, coding assistants, or automation tools that need structured codebase understanding as input.

### Tertiary: Open Source Maintainers
Project maintainers who want to make their repos more accessible to AI-assisted contributors.

## User Stories

### US-1: First-Time Setup
**As a** developer who just installed Cartographer,
**I want to** run a single command to generate a context map,
**So that** my AI coding assistant immediately understands my project structure.

**Acceptance Criteria:**
- `npx ai-cartographer init` (or equivalent) works in any git repo
- Generates `.ai/context-map.md` in under 60 seconds for a typical repo (<1000 files)
- Output is human-readable and useful without any configuration
- Adds `.ai/` to the project (not gitignored by default — the map should be committed)

### US-2: Semantic File Descriptions
**As a** developer reviewing the context map,
**I want to** see meaningful descriptions of each file's purpose,
**So that** both I and my AI agent understand the codebase at a glance.

**Acceptance Criteria:**
- Each file entry includes a one-line semantic description generated by LLM
- Files are classified into tiers for cost-efficient analysis (see FR-2)
- Auto-skip tier: config files, lockfiles, generated code get pattern-based descriptions without API calls
- Example output:
  ```
  src/auth/utils.ts -> "Handles JWT validation, token refresh, and password hashing"
  src/db/migrations/001.sql -> "Creates users table with email, role, and timestamp columns"
  package-lock.json -> [auto-skip: dependency lockfile]
  ```

### US-3: Auto-Maintenance
**As a** developer who has set up Cartographer,
**I want** the context map to update automatically when I make changes,
**So that** it never becomes stale or misleading.

**Acceptance Criteria:**
- Git hook option: post-commit hook updates the map incrementally
- CLI option: `ai-cartographer refresh` re-scans and updates
- Incremental updates: only re-analyze changed files, not the full repo
- Staleness detection: warn if map is older than N commits behind HEAD

### US-4: Token-Efficient Output
**As an** AI agent consuming the context map,
**I want** a concise, well-structured index,
**So that** I can understand the full project in minimal tokens.

**Acceptance Criteria:**
- Full context map for a 500-file project fits under 4,000 tokens
- Hierarchical grouping by directory with rollup summaries
- No redundant information (don't repeat directory paths for every file)
- Section headers for quick scanning (e.g., "## Core Business Logic", "## Tests")

### US-5: Configuration
**As a** developer with a large or unusual project,
**I want to** configure which paths are indexed and which are ignored,
**So that** the map focuses on what matters.

**Acceptance Criteria:**
- Config file: `.ai/cartographer.config.json` (or `.yaml`)
- Configurable: ignored paths (e.g., `node_modules`, `dist`, `.git`)
- Configurable: key entry points (files that should be described in more detail)
- Configurable: output path (default `.ai/context-map.md`)
- Sensible defaults that work without any configuration

### US-6: AI Tool Integration
**As a** developer using Cursor, Claude Code, or Copilot,
**I want** Cartographer to integrate seamlessly with my tool,
**So that** my agent automatically loads the context map.

**Acceptance Criteria:**
- Claude Code: outputs in a format compatible with CLAUDE.md / system prompts
- Cursor: compatible with `.cursorrules` or context file conventions
- Copilot: works as a workspace-level context file
- Documentation explains integration steps for each tool

## Requirements

### Functional Requirements

**FR-1: CLI Interface**
- `init` — Generate context map for the first time
- `refresh` — Update the context map (incremental, only re-analyzes changed files)
- `status` — Show map freshness (commits behind, files changed, cached vs stale)
- `config` — Manage configuration interactively
- Global options: `--verbose`, `--format`, `--output`, `--free` (no API key mode), `--dry-run` (show file count, tier breakdown, and estimated cost without scanning)

**FR-2: LLM Analysis Engine (Core)**
- All semantic descriptions generated by LLM — no custom language parsers needed
- Support Claude and OpenAI APIs (configurable provider and model)
- **Tiered file classification** to minimize API costs:
  - **Auto-skip tier**: Files described by pattern matching without API calls — lockfiles (`package-lock.json`, `yarn.lock`), generated code (`*.min.js`, `*.d.ts`), config files (`.eslintrc`, `tsconfig.json`), binary files, `LICENSE`, `CHANGELOG`
  - **Batch tier**: Files analyzed in batches of 10-20 per API call — test files, utilities, simple modules. LLM receives filenames + key content snippets and returns one-line descriptions for each
  - **Deep tier**: Key entry points and core business logic analyzed individually for richer descriptions — configurable via "key entry points" in config
- **Model routing**: Use a fast/cheap model (e.g., Haiku) for batch tier, capable model (e.g., Sonnet) for deep tier. Configurable per tier.
- **Content-hash caching**: SHA-256 hash of each file's content stored alongside descriptions. On refresh, only re-analyze files whose hash changed. Cache stored in `.ai/.cache/` (gitignored)
- **Batched API calls**: Bundle multiple files into single prompts to reduce API call count by ~90%
- **Rate limiting**: Configurable concurrency and requests-per-minute to stay within API limits
- **Graceful degradation**: If API fails mid-scan, use cached descriptions for unchanged files and mark failed files as "pending"

**FR-3: Free Mode (Fallback)**
- `--free` flag generates a basic directory tree with filename-derived descriptions (no API key required)
- Pattern-based inference: `*.test.ts` → "Test file", `migrations/*.sql` → "Database migration", `index.ts` → "Module entry point"
- Useful for quick previews or repos where API access isn't available
- No custom parsers — just smart pattern matching on filenames and directory structure

**FR-4: Output Generation**
- Primary output: `.ai/context-map.md` (Markdown, LLM-optimized)
- Structured sections: directory tree with descriptions, key entry points, module relationships
- Optional: structured output format (JSON/YAML) — architect's decision
- Include metadata: generation timestamp, repo stats, config used

**FR-5: Auto-Maintenance**
- Git hook installer: `ai-cartographer hooks install`
- Post-commit hook: incrementally updates map for changed files only (uses content-hash cache)
- Diff-aware: compares file hashes against `.ai/.cache/` to determine what changed
- Incremental refresh cost: near-zero for typical commits (1-20 files)
- Configurable: auto-commit updated map or leave as unstaged change

**FR-6: Ignore / Include Rules**
- Default ignores: `node_modules`, `.git`, `dist`, `build`, `vendor`, `__pycache__`, binary files
- User-configurable via config file
- Support glob patterns
- Support "key entry points" that get enriched descriptions

### Non-Functional Requirements

**NFR-1: Performance**
- Initial scan: <60 seconds for repos under 1,000 files
- Incremental refresh: <5 seconds for typical commits (1-20 files changed)
- Memory: <256MB for repos under 10,000 files

**NFR-2: Token Efficiency**
- Context map for 500-file project: <4,000 tokens
- Context map for 2,000-file project: <12,000 tokens
- Compression ratio: at least 100x vs. concatenating all file contents

**NFR-3: Reliability**
- Never crash on malformed files — skip with a warning
- Never modify source code — read-only access to the codebase
- Idempotent: running twice produces the same output

**NFR-4: Portability**
- Works on macOS, Linux, Windows
- No system dependencies beyond the chosen runtime
- Single command installation

## Success Criteria

1. **Navigation accuracy**: An agent provided only with context-map.md can correctly identify the right file to edit for a specific bug fix, without searching the file tree — measured across 10 diverse test repos
2. **Token savings**: Agents using the context map consume at least 40% fewer tokens in the orientation phase compared to agents without it
3. **Adoption signal**: 100+ GitHub stars within 3 months of launch
4. **Install experience**: From `npx ai-cartographer init` to usable context map in under 2 minutes on a fresh repo

## Constraints & Assumptions

- **LLM-first analysis**: API key required for full functionality; `--free` fallback mode available without API key
- **MIT license**: maximum adoption, no usage restrictions
- **Runtime**: architect's decision — evaluate Node.js (TypeScript), Rust, and Go based on install experience, performance, and ecosystem fit
- **Output format**: architect decides structured format (JSON vs YAML) based on integration needs
- **No data collection**: the tool runs locally, no telemetry, no phone-home
- **Git dependency**: assumes the project is a git repository (for hooks and change detection)

## Out of Scope

- IDE plugins or extensions (v1 is CLI only)
- Real-time file watching (use git hooks or manual refresh)
- Code generation or modification (read-only tool)
- Hosting or SaaS version
- Support for non-git version control systems
- Generating documentation beyond the context map (no API docs, no changelogs)
- Multi-repo / workspace support (single repo per map in v1)

## Cost Estimates

Estimated API costs using Claude Sonnet with batching and tiered analysis:

| Repo Size | Analyzable Files | Est. API Cost (init) | Est. Cost (refresh, ~10 files) |
|-----------|-----------------|---------------------|-------------------------------|
| Small (50 files) | ~35 | ~$0.15 | ~$0.01 |
| Medium (500 files) | ~350 | ~$1.50 | ~$0.02 |
| Large (2,000 files) | ~1,400 | ~$5.00 | ~$0.03 |
| Legacy (10,000 files) | ~7,000 | ~$20.00 | ~$0.05 |

*"Analyzable files" excludes auto-skip tier (lockfiles, generated code, config). Costs assume batching of 15 files per API call and model routing (Haiku for batch tier, Sonnet for deep tier).*

## Dependencies

- Git (for change detection and hooks)
- LLM API key (Claude or OpenAI) — required for full functionality, free mode available without
- Package registry account (npm, crates.io, or similar for distribution)

## Risks

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|------------|
| API costs surprise users on large repos | Medium | High | Show cost estimate before scan (`--dry-run`), tiered analysis, caching, model routing |
| API key requirement reduces adoption | Medium | Medium | `--free` fallback mode, clear value proposition justifies API cost |
| Context maps become stale despite hooks | Low | High | Staleness warnings, CI integration option, `status` command |
| Large repos (10k+ files) produce unwieldy maps | Medium | Medium | Hierarchical grouping, configurable depth, directory-level rollups |
| Runtime choice limits adoption | Low | Medium | Let architect evaluate; Node.js is safest default for dev tool ecosystem |
| Competing tools emerge (Cursor/Copilot build this in) | Medium | Medium | Move fast, establish as the open standard before tools build proprietary versions |
| LLM API rate limits slow down large scans | Low | Medium | Configurable concurrency, batch calls reduce total requests, progress indicator |
