---
name: LLM client with provider abstraction and batching
status: open
created: 2026-02-17T16:35:56Z
updated: 2026-02-17T18:36:10Z
github: https://github.com/gilpaAI/ai-cartographer/issues/5
depends_on: [2]
parallel: true
conflicts_with: []
---

# Task: LLM client with provider abstraction and batching

## Description
Build the LLM client that handles all API communication. Supports Claude and OpenAI with a common interface. Implements batched file analysis (10-20 files per call), model routing per tier, rate limiting, and retry logic.

## Acceptance Criteria
- [ ] Provider interface: analyze(files) â†’ descriptions[]
- [ ] AnthropicProvider using @anthropic-ai/sdk
- [ ] OpenAIProvider using openai sdk
- [ ] Batch prompt: sends multiple files (path + content snippet) in one call, returns structured one-line descriptions
- [ ] Deep prompt: sends full file content, returns rich description
- [ ] Model routing: configurable model per tier (e.g., Haiku for batch, Sonnet for deep)
- [ ] Rate limiting: configurable max concurrent requests and requests-per-minute
- [ ] Retry logic: exponential backoff on rate limit errors (429)
- [ ] Graceful degradation: if API call fails after retries, mark files as "pending" and continue
- [ ] Progress callback for CLI progress display

## Technical Details
- Provider interface: { analyzeBatch(files: FileEntry[]): Promise<FileDescription[]>, analyzeDeep(file: FileEntry): Promise<FileDescription> }
- Batch size configurable (default 15 files per call)
- Content snippet extraction: first 50 lines + exports/imports for batch mode
- Full content for deep mode (truncate at 8K tokens)
- Config: provider, apiKey (or env var), batchModel, deepModel, maxConcurrent, rpmLimit

## Dependencies
- [ ] Task 2 (config structure for LLM settings)

## Effort Estimate
- Size: L
- Hours: 10
- Parallel: true (can develop alongside 3, 4, 6)

## Definition of Done
- [ ] Code implemented in src/llm/client.ts, src/llm/anthropic.ts, src/llm/openai.ts
- [ ] Both providers tested with real API calls
- [ ] Batching produces correct descriptions
- [ ] Rate limiting prevents 429 errors
